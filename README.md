# MIAPPExSOSA

The integration of proximal sensing, robotics, and remote sensing into plant phenotyping has created an interdisciplinary data landscape that is vast and complex. While enabling non-destructive measurements under field conditions, these technologies generate heterogeneous datasets that challenge effective data management and interoperability. Current metadata standards, such as the Minimum Information About a Plant Phenotyping Experiment (MIAPPE), provide a crucial foundation but lack explicit constructs for describing sensors, platforms, and computational workflows central to modern, technology-driven phenotyping. This hinders the findability, accessibility, interoperability, and reusability (FAIR) of data and limits the potential for advanced data integration and analysis. To bridge this gap, we propose a novel, ontology-based data model that semantically extends MIAPPE by integrating concepts from the Semantic Sensor Network (SSN/SOSA) ontology. This model formalizes the relationship between biological studies, observational procedures, sensor systems, and derived data, creating a unified framework for documenting interdisciplinary field phenotyping experiments. A primary objective of this model is to serve as a canonical schema for converting disparate, tabular phenotyping metadata into a structured, machine-readable knowledge graph. This graph representation is not only inherently FAIR but also provides the foundational structure for future applications, such as the training of graph neural networks (GNNs) to discover contextual patterns across experiments.


## Project Overview

This Project is seperated into different Phases with the intent to increase FAIR data for the plant phenotyping community with a somewhat holistic and sustainalbe approach. A further motivation is the minimal extend regarding developing new tools, but instead to refer to what is already there. 

The current state of data within the domain of plant phenotyping are prone to the following issues: data is rarely shared with sufficient metadata, to allow data reuse. The format of data is hard to digest for machines, demping the potential of data in regards of data discovery, interoperability between other data, automation for robotics, or purpose of data which is valuable in machine learning applications. There are sevarrl ways to approach these issues. Metadata, which is a desciption of data can help understand a dataset, since metadata can give information on purpose, content, methodology, structure or provenance of data. In its most basic format, this can be realized with an attached file or with a html-based representation on a website of a repository. In practice, README-files are commonly enclosed to a set of files, with the purpose to help a human-agent to understand the content of the dataset. 

But in case of describing entities, methods or objectives, there is usually some room of interpretation or terms might differ totally in different domains. A solution of this is to define a set of controlled vocabularies. They allow the usage accessible and referencable definitions. This can be used to fill in forms or checklists, each value or instance can be directly associated with a certain definition. The idea behind Metadata Standards are that Data-Entities can be annotated across different databases and repositories, instead of having for each databse a unique solution. An approach like this was realized in MIAME (Minimum Information about a Microarray Experiment) with the goal to give minimum information that is required for an experiment to be easily interpreted and that results can be independently be verified. This approach has been realized in different domains such as CIMR (Core Information for Metabololmic Reporting), MIACA (Minimum Information about a Cellular Assay), MIMIx (Minimum Information for Molecular Interaction Experiments) or MIAPPE (Minimum Information about Plant Phenotyping Experiements). They in general provide a community defined set of terms in a checklist format.

With the resent developement in artificial intelligence in terms of AI-agents and developemnts in sensing systems in the domain of phenotyping leading to automated systems or integrating methodos from the remote sensing community it becomes more important to have data in shapes and formats, that are also understandable to machines across discilplines. One approach to realize this is to align data with ontologies, which is not only provide referencable terms but also relationships and restrictions between entities, which allows the development of graphs which capture semantic relations.

| PHASE | DESCRIPTION |
| ----- | ----------- |
| Metadata-Standard | The domain of Plant Phenotyping is utilizing methods adapted from the remote sensing community, in order to capture traits such as Fluorescence, canopy structure, NVDI, stress, etc by mounting certain sensors to platforms such as drones, aircrafts or satellites, allowing detection of plant properties on larger spatial scales, in shorter amounts of time and without the need of direct interference with the plant development. While MIAPPE provides a set of minimum information which allows to descibe a phenotyping experiement the current version of MIAPPE misses to implement sensor reletad terms, So we provide an extended version of MIAPPE which takes Terms from the Semantic Sensor Network Ontology in order to meaningfully add information regarding Sensor-Data. This phase mainly consists of making a draft for the extended checklist format and realize it for newly published datasets (see Benchmark Dataset) |
| Data Model Builder | This Phase Is building on the above described development of an extension of an already existing Metadata Standard and convert it into a Data model by merging the data models of MIAPPE, SSN and SOSA and find edges which bring Entities of these ontologies into a new data model. This Datamodel can be used as a new Ontology, and be thought to be flexible extendable in a manner that new ontologies can be added or modular exchanged, dependend on the nature of the investigation or the experiement, in order to 1) keep the minimum aaproach, 2) not invent new tools and 3) by keeping the idea of modularity, to be flexible, allowing to align with the heterogeneous nature of the data within the domain, and also allowing the potential of access from different data domains, by thinking of the data model as a dynamic graph structure |
| Knowledge Base | In order to have a Metadata Standard to be established as a Standard it is mandetory, that this 'standard' gets recorgnized and used. Therefor we provide a Knowledge Base, where we provide Information oon MIAPPe and SSN/SOSA, the Usage of the MIAPPE extension with a tutorail illustrated with an example in order to help researchers to have an easier time with there struggle in giving metadata when publishing there metadata or when thinking about developing a certain inhouse data-infrastructure. This Knowledge Base is going to be avaialble on the Internet |
| Knowledge Graph Converter | The next phase tries to convert the checklist format based on the underlying data model into a linked-data format, which the basic idea of giving the potential that each datafile, description or variable of a dataset can broad into a semantic context, to increase interoperability by providing knowledge graph like structures that can be linke to other datasets and to increase the findability, by utilizing methods from search engines and the semantic web |
| Graph Embedding | The Final Phase of the project revolves arround the idea, that datasets, which are converted into graphlike structures, can be embedded into represetation spaces / concept spaces (with a certain degree of concept resolution) in order to allow datasets to be compared regarding their (spatial/temporal/methodogical/biological/contextual) similarity. In order to do so, embedding models are to be developed, trained and validated regarding there performance of finding similarities within datasets |




