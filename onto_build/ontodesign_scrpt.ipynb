{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb9483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ppeo', 'sosa', 'ssn']\n",
      "investigation\n",
      " - hasPersonWithRole, domain: [ppeo.investigation | ppeo.study], range: [ppeo.role], type: <class 'owlready2.prop.ObjectPropertyClass'>\n",
      " - hasPart, domain: [], range: [], type: <class 'owlready2.prop.ObjectPropertyClass'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    def _load_classes(self):\\n        for ont in self.onto.imported_ontologies:\\n            if ont.name in CLASSES:\\n                for class_name in ont.classes():\\n                    if class_name.name in CLASSES[ont.name]:\\n                        self.make_class(self.unify_name(class_name.name), parent_class=class_name)\\n\\n    def make_class(self, class_name, parent_class=Thing):\\n        with self.onto:\\n            NewClass = types.new_class(class_name, (parent_class,))\\n            NewClass.is_a = [parent_class]\\n\\n        return NewClass\\n '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ontology Designer\n",
    "\n",
    "\n",
    "import types\n",
    "from owlready2 import get_ontology, Thing, ObjectPropertyClass\n",
    "import rdflib\n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Temporary Ontology Link\n",
    "# ONTOLOGY_PATH = r'https://github.com/gryvity/MIAPPEx/onto_build/lab_ontologies/miappeXsosa.owl'\n",
    "ONTOLOGY_PATH = r'miappeXsosa/miappeXsosa.owl'\n",
    "\n",
    "# Import existiing Ontologies\n",
    "IMPORT_LOCAL = {\n",
    "    'ppeo' : os.path.join(r'external/ppeo.owl'),\n",
    "    'sosa' : os.path.join(r'external/sosa.owl'), \n",
    "    'ssn'  : os.path.join(r'external/ssn.ttl')\n",
    "    }\n",
    "\n",
    "\n",
    "# THESE NEED A REDESIGN AS WELL\n",
    "ONTOLOGIES_IMPORT = {\n",
    "    'ppeo' : [],\n",
    "    'sosa' : [],\n",
    "    'ssn'  : []\n",
    "}\n",
    "\n",
    "CLASSES = ONTOLOGIES_IMPORT.copy()\n",
    "# DATA_PROPERTIES = ONTOLOGIES_IMPORT.copy()\n",
    "# OBJECT_PROPERTIES = ONTOLOGIES_IMPORT.copy()\n",
    "\n",
    "# PROPERTIES = {'domain': None, 'range': None, 'name': None}\n",
    "\n",
    "# set classes\n",
    "\n",
    "\n",
    "# FOR NOW WE WILL PICK A FEW CLASSES TO TEST THE FUNCTIONALITY (LATER WE WILL IMPORT EVERYTHING)\n",
    "CLASSES['ppeo'].extend(\n",
    "    [\n",
    "    'investigation',\n",
    "    'person',\n",
    "    'study',\n",
    "    'observation_unit',\n",
    "    'observed_variable',\n",
    "    'biological_material',\n",
    "    'factor',\n",
    "    'environment'\n",
    "    ]\n",
    ")\n",
    "\n",
    "CLASSES['sosa'].extend(\n",
    "    [\n",
    "    'Observation',\n",
    "    'FeatureOfInterest',\n",
    "    'Procedure',\n",
    "    'ObservableProperty',\n",
    "    'Sensor',\n",
    "    'Platform'\n",
    "    ]\n",
    ")\n",
    "\n",
    "CLASSES['ssn'].extend(\n",
    "    [\n",
    "    'System',\n",
    "    'Input',\n",
    "    'Output',\n",
    "    'Deployment'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class OntologyBuilder(object):\n",
    "    IMPORT = {\n",
    "        'ppeo' : ('http://ppeo.org/ontology/ppeo.owl', 'owl'),\n",
    "        'sosa' : ('http://www.w3.org/ns/sosa/', 'ttl'),\n",
    "        'ssn'  : ('http://www.w3.org/ns/ssn/', 'ttl')\n",
    "    }\n",
    "\n",
    "    def __init__(self, onto_IRI=ONTOLOGY_PATH, onto_path=ONTOLOGY_PATH, import_local=IMPORT_LOCAL, refresh=True):\n",
    "\n",
    "        self.onto_path = onto_path\n",
    "\n",
    "        \"\"\"Here let us collect all available classes and object properties in form as \n",
    "        \n",
    "        [classname] : {\n",
    "            'superclasses' : [list of superclasses (is_a)],\n",
    "            'iri' : class_iri,\n",
    "            'name' : classname,\n",
    "            'comment' : comment,\n",
    "            'index' : index in imported ontologies,\n",
    "            'imported_from' : self.onto.imported_ontologies[index].name\n",
    "\n",
    "            'object_properties' : {\n",
    "                ['property_name'] : {\n",
    "                    'iri' : property_iri,\n",
    "                    'comment' : comment,\n",
    "                    'domain' : domain,\n",
    "                    'range' : range}\n",
    "                }\n",
    "            'data_properties' : {\n",
    "                ['property_name'] : {\n",
    "                    'iri' : property_iri,\n",
    "                    'comment' : comment,\n",
    "                    'domain' : domain,\n",
    "                    'range' : range}\n",
    "                }\n",
    "        \n",
    "        \"\"\"\n",
    "        self.onto_structure = {\n",
    "\n",
    "        }\n",
    "\n",
    "        if os.path.exists(onto_path) and not refresh:\n",
    "            self.onto = get_ontology(f'file://{os.path.abspath(onto_path)}').load()\n",
    "        else:\n",
    "            self.onto = get_ontology(onto_IRI)\n",
    "\n",
    "        if refresh:\n",
    "            self.onto.imported_ontologies.clear()\n",
    "        \n",
    "       \n",
    "        if import_local:\n",
    "            for label, path in import_local.items():\n",
    "                self.onto.imported_ontologies.append(self._load_local_import(path))\n",
    "                self.onto.imported_ontologies[-1].name = label\n",
    "\n",
    "        self._load_import_content()\n",
    "\n",
    "    def _load_import_content(self):\n",
    "        pass\n",
    "       \n",
    "    def _load_local_import(self, path):\n",
    "        match path.split('.')[-1].lower():\n",
    "            case 'owl':\n",
    "                return get_ontology(path).load()\n",
    "            case 'ttl':\n",
    "                g = rdflib.Graph()\n",
    "                g.parse(path, format='turtle')\n",
    "                with io.BytesIO(g.serialize(format='pretty-xml').encode('utf-8')) as temp_file:\n",
    "                    return get_ontology(path).load(fileobj=temp_file)\n",
    "                \n",
    "            case _:\n",
    "                raise ValueError(f'Unsupported file format: {path}')\n",
    "    \n",
    "    def save(self, path=None):\n",
    "        if path is None:\n",
    "            path = self.onto_path\n",
    "        else:\n",
    "            if not os.path.exists(os.path.dirname(path)):\n",
    "                os.makedirs(os.path.dirname(path))\n",
    "        self.onto.save(file = path, format = 'rdfxml')\n",
    "\n",
    "    def unify_name(self, name):\n",
    "        if name.islower():\n",
    "            name = name.title()\n",
    "        if '_' in name:\n",
    "            return name.replace('_', ' ').title().replace(' ', '')\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    def _load_classes_test(self):\n",
    "        for ont in self.onto.imported_ontologies:\n",
    "            if ont.name in CLASSES:\n",
    "                for class_name in ont.classes():\n",
    "                    if class_name.name in CLASSES[ont.name]:\n",
    "                        self.make_class(self.unify_name(class_name.name), parent_class=class_name)\n",
    "\n",
    "    def make_class(self, class_name, parent_class=Thing):\n",
    "        with self.onto:\n",
    "            NewClass = types.new_class(class_name, (parent_class,))\n",
    "            NewClass.is_a = [parent_class]\n",
    "         \n",
    "        return NewClass\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Test\n",
    "\n",
    "onto = OntologyBuilder()\n",
    "\n",
    "onto.save()\n",
    "    \n",
    "\n",
    "print([test.name for test in onto.onto.get_imported_ontologies()])\n",
    "\n",
    "ns = 'ppeo'\n",
    "cn = 'investigation'\n",
    "\n",
    "# Step 1: Identify Index of imported Ontology\n",
    "inx = [o.name for o in onto.onto.get_imported_ontologies()].index(ns)\n",
    "\n",
    "picked_cl = [c for c in onto.onto.get_imported_ontologies()[inx].classes() if c.name == cn].pop()\n",
    "\n",
    "print(picked_cl.name)\n",
    "for prop in [p for p in picked_cl.get_class_properties() if isinstance(p, ObjectPropertyClass)]:\n",
    "    print(f' - {prop.name}, domain: {prop.domain}, range: {prop.range}, type: {type(prop)}')\n",
    "\n",
    "# Based on the code above we redesign the following mehtods\n",
    "\n",
    "# class Test(OntologyBuilder):\n",
    "#     def __init__(self, onto_IRI=ONTOLOGY_PATH, onto_path=ONTOLOGY_PATH, import_local=IMPORT_LOCAL, refresh=True):\n",
    "#         super().__init__(onto_IRI, onto_path, import_local, refresh )\n",
    "#         self.onto_content = {}\n",
    "\n",
    "#     def _load_ontology_content(self):\n",
    "#         for ont \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    def _load_classes(self):\n",
    "        for ont in self.onto.imported_ontologies:\n",
    "            if ont.name in CLASSES:\n",
    "                for class_name in ont.classes():\n",
    "                    if class_name.name in CLASSES[ont.name]:\n",
    "                        self.make_class(self.unify_name(class_name.name), parent_class=class_name)\n",
    "\n",
    "    def make_class(self, class_name, parent_class=Thing):\n",
    "        with self.onto:\n",
    "            NewClass = types.new_class(class_name, (parent_class,))\n",
    "            NewClass.is_a = [parent_class]\n",
    "         \n",
    "        return NewClass\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43117d76",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "\n",
    "- Make a new ontology which imports a small sett of classes from sosa, ssn and ppeo\n",
    "- Find a visualization tool (or draw a data model yourself)\n",
    "- For each class create a json-object which serves as a container of data\n",
    "- Write a converter from MIAPPE tables to JSON-LD format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97ca4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sosa.ActuatableProperty\n",
      "sosa.Actuation\n",
      "sosa.Actuator\n",
      "sosa.FeatureOfInterest\n",
      "sosa.ObservableProperty\n",
      "sosa.Observation\n",
      "sosa.Platform\n",
      "sosa.Procedure\n",
      "sosa.Result\n",
      "sosa.Sample\n",
      "sosa.Sampler\n",
      "sosa.Sampling\n",
      "sosa.Sensor\n"
     ]
    }
   ],
   "source": [
    "# Try to load an ontology from the internet\n",
    "from owlready2 import get_ontology\n",
    "import rdflib\n",
    "\n",
    "test_onto1 = get_ontology('http://purl.org/ppeo/PPEO.owl').load()\n",
    "\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse('https://www.w3.org/ns/ssn/', format='turtle')\n",
    "\n",
    "with io.BytesIO(g.serialize(format='pretty-xml').encode('utf-8')) as temp_file:\n",
    "    test_onto2 = get_ontology('http://www.w3.org/ns/ssn/').load(fileobj=temp_file)\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse('https://www.w3.org/ns/sosa/', format='turtle')\n",
    "with io.BytesIO(g.serialize(format='pretty-xml').encode('utf-8')) as temp_file:\n",
    "    test_onto3 = get_ontology('http://www.w3.org/ns/sosa/').load(fileobj=temp_file)\n",
    "\n",
    "for cls in test_onto3.classes():\n",
    "    if str(cls).startswith('sosa'):\n",
    "        print(cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
